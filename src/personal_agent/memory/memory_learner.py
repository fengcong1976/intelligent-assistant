"""
Memory Learner - è®°å¿†å­¦ä¹ å™¨
ä»å¯¹è¯ä¸­è‡ªåŠ¨æå–å’Œæ›´æ–°è®°å¿†
"""
from typing import Dict, List, Optional, Tuple
from datetime import datetime
from loguru import logger
import re

from .unified_memory import UnifiedMemory


class MemoryLearner:
    """
    è®°å¿†å­¦ä¹ å™¨ - ä»å¯¹è¯ä¸­è‡ªåŠ¨å­¦ä¹ 
    
    åŠŸèƒ½ï¼š
    1. æå–ç”¨æˆ·ä¿¡æ¯ï¼ˆå§“åã€ä½ç½®ã€ç”Ÿæ—¥ç­‰ï¼‰
    2. å­¦ä¹ ç”¨æˆ·åå¥½
    3. è¯†åˆ«é‡è¦äº‹ä»¶
    4. æå–å…³é”®ä¿¡æ¯ä½œä¸ºå¤‡å¿˜
    """
    
    def __init__(self, memory: UnifiedMemory = None):
        self.memory = memory or UnifiedMemory()
        
        self.extraction_patterns = {
            "name": [
                (r"æˆ‘å«([^\sï¼Œã€‚ï¼ï¼Ÿ,]+)", 0.9),
                (r"æˆ‘æ˜¯([^\sï¼Œã€‚ï¼ï¼Ÿ,]+)", 0.7),
                (r"æˆ‘çš„åå­—(?:å«|æ˜¯)([^\sï¼Œã€‚ï¼ï¼Ÿ,]+)", 0.9),
                (r"ä½ å¯ä»¥å«æˆ‘([^\sï¼Œã€‚ï¼ï¼Ÿ,]+)", 0.9),
            ],
            "nickname": [
                (r"æˆ‘çš„æ˜µç§°(?:å«|æ˜¯)([^\sï¼Œã€‚ï¼ï¼Ÿ,]+)", 0.9),
                (r"å¤§å®¶å«æˆ‘([^\sï¼Œã€‚ï¼ï¼Ÿ,]+)", 0.8),
            ],
            "location": [
                (r"æˆ‘åœ¨([^\sï¼Œã€‚ï¼ï¼Ÿ,]+)", 0.8),
                (r"æˆ‘ä½åœ¨([^\sï¼Œã€‚ï¼ï¼Ÿ,]+)", 0.9),
                (r"æˆ‘çš„ä½ç½®(?:æ˜¯|åœ¨)([^\sï¼Œã€‚ï¼ï¼Ÿ,]+)", 0.9),
                (r"æˆ‘åœ¨([^\sï¼Œã€‚ï¼ï¼Ÿ,]+)(?:å·¥ä½œ|ç”Ÿæ´»)", 0.8),
            ],
            "city": [
                (r"æˆ‘åœ¨([^\sï¼Œã€‚ï¼ï¼Ÿ,]+)å¸‚", 0.9),
                (r"æˆ‘ä½åœ¨([^\sï¼Œã€‚ï¼ï¼Ÿ,]+)å¸‚", 0.9),
                (r"æˆ‘çš„åŸå¸‚(?:æ˜¯|åœ¨)([^\sï¼Œã€‚ï¼ï¼Ÿ,]+)", 0.9),
            ],
            "birthday": [
                (r"æˆ‘çš„ç”Ÿæ—¥(?:æ˜¯|åœ¨)(\d{1,2})æœˆ(\d{1,2})[æ—¥å·]?", 0.9),
                (r"æˆ‘(\d{1,2})æœˆ(\d{1,2})[æ—¥å·]?å‡ºç”Ÿ", 0.9),
                (r"æˆ‘çš„ç”Ÿæ—¥(?:æ˜¯|åœ¨)(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})[æ—¥å·]?", 0.9),
            ],
            "email": [
                (r"æˆ‘çš„é‚®ç®±(?:æ˜¯|:)?\s*([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})", 0.95),
                (r"å‘åˆ°([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})", 0.7),
            ],
            "phone": [
                (r"æˆ‘çš„ç”µè¯(?:æ˜¯|:)?\s*(1[3-9]\d{9})", 0.9),
                (r"æˆ‘çš„æ‰‹æœº(?:æ˜¯|:)?\s*(1[3-9]\d{9})", 0.9),
            ],
            "occupation": [
                (r"æˆ‘æ˜¯([^\sï¼Œã€‚ï¼ï¼Ÿ,]+)(?:å·¥ç¨‹å¸ˆ|è®¾è®¡å¸ˆ|ç»ç†|è€å¸ˆ|åŒ»ç”Ÿ|å­¦ç”Ÿ)", 0.8),
                (r"æˆ‘æ˜¯ä¸€å([^\sï¼Œã€‚ï¼ï¼Ÿ,]+)", 0.7),
                (r"æˆ‘çš„èŒä¸š(?:æ˜¯|:)([^\sï¼Œã€‚ï¼ï¼Ÿ,]+)", 0.9),
            ],
            "company": [
                (r"æˆ‘åœ¨([^\sï¼Œã€‚ï¼ï¼Ÿ,]+)å·¥ä½œ", 0.8),
                (r"æˆ‘çš„å…¬å¸(?:æ˜¯|:)([^\sï¼Œã€‚ï¼ï¼Ÿ,]+)", 0.9),
            ],
        }
        
        self.preference_patterns = {
            "communication_style": [
                (r"æˆ‘å–œæ¬¢(ç®€æ´|è¯¦ç»†|ç®€çŸ­|è¯¦ç»†)çš„å›å¤", "ç®€æ´å›å¤" if "ç®€æ´" in r"æˆ‘å–œæ¬¢ç®€æ´çš„å›å¤" else "è¯¦ç»†å›å¤", 0.8),
                (r"è¯·(ç®€æ´|ç®€çŸ­)ä¸€ç‚¹", "ç®€æ´å›å¤", 0.9),
                (r"è¯·(è¯¦ç»†|å…·ä½“)ä¸€ç‚¹", "è¯¦ç»†å›å¤", 0.9),
            ],
            "language": [
                (r"è¯·ç”¨(ä¸­æ–‡|è‹±æ–‡|ç²¤è¯­)å›å¤", lambda m: m.group(1), 0.9),
                (r"æˆ‘å–œæ¬¢ç”¨(ä¸­æ–‡|è‹±æ–‡|ç²¤è¯­)äº¤æµ", lambda m: m.group(1), 0.8),
            ],
            "time_format": [
                (r"æˆ‘å–œæ¬¢(24å°æ—¶|12å°æ—¶)åˆ¶", lambda m: m.group(1), 0.8),
            ],
            "general": [
                (r"æˆ‘å–œæ¬¢([^\sï¼Œã€‚ï¼ï¼Ÿ,]+)", lambda m: m.group(1), 0.6),
                (r"æˆ‘åå¥½([^\sï¼Œã€‚ï¼ï¼Ÿ,]+)", lambda m: m.group(1), 0.7),
                (r"æˆ‘æ¯”è¾ƒå–œæ¬¢([^\sï¼Œã€‚ï¼ï¼Ÿ,]+)", lambda m: m.group(1), 0.7),
                (r"æˆ‘ä¸å–œæ¬¢([^\sï¼Œã€‚ï¼ï¼Ÿ,]+)", lambda m: f"ä¸å–œæ¬¢{m.group(1)}", 0.7),
            ],
        }
        
        self.event_patterns = [
            (r"(\d{1,2})æœˆ(\d{1,2})[æ—¥å·]?æˆ‘æœ‰([^\sï¼Œã€‚ï¼ï¼Ÿ,]+)", "date_event"),
            (r"(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})[æ—¥å·]?æ˜¯([^\sï¼Œã€‚ï¼ï¼Ÿ,]+)", "date_event"),
            (r"ä¸‹å‘¨([ä¸€äºŒä¸‰å››äº”å…­æ—¥å¤©])(?:æœ‰|æ˜¯|è¦)([^\sï¼Œã€‚ï¼ï¼Ÿ,]+)", "weekday_event"),
            (r"æ˜å¤©(?:æœ‰|æ˜¯|è¦)([^\sï¼Œã€‚ï¼ï¼Ÿ,]+)", "tomorrow_event"),
            (r"åå¤©(?:æœ‰|æ˜¯|è¦)([^\sï¼Œã€‚ï¼ï¼Ÿ,]+)", "day_after_event"),
        ]
        
        self.important_keywords = [
            "ç”Ÿæ—¥", "ç»“å©š", "çºªå¿µæ—¥", "ä¼šè®®", "é¢è¯•", "è€ƒè¯•", 
            "èˆªç­", "ç«è½¦", "é¢„çº¦", "æˆªæ­¢", "é‡è¦"
        ]
    
    def learn_from_message(self, role: str, content: str) -> Dict:
        """
        ä»æ¶ˆæ¯ä¸­å­¦ä¹ 
        
        Args:
            role: æ¶ˆæ¯è§’è‰² (user/assistant)
            content: æ¶ˆæ¯å†…å®¹
        
        Returns:
            å­¦ä¹ ç»“æœ
        """
        if role != "user":
            return {"learned": False, "reason": "åªä»ç”¨æˆ·æ¶ˆæ¯å­¦ä¹ "}
        
        results = {
            "learned": False,
            "profile_updates": [],
            "preference_updates": [],
            "events_detected": [],
            "notes_added": []
        }
        
        profile_updates = self._extract_user_info(content)
        results["profile_updates"] = profile_updates
        if profile_updates:
            results["learned"] = True
        
        preference_updates = self._extract_preferences(content)
        results["preference_updates"] = preference_updates
        if preference_updates:
            results["learned"] = True
        
        events_detected = self._extract_events(content)
        results["events_detected"] = events_detected
        if events_detected:
            results["learned"] = True
        
        notes_added = self._extract_important_info(content)
        results["notes_added"] = notes_added
        if notes_added:
            results["learned"] = True
        
        if results["learned"]:
            logger.info(f"ğŸ§  ä»æ¶ˆæ¯ä¸­å­¦ä¹ : {len(profile_updates)} æ¡£æ¡ˆ, {len(preference_updates)} åå¥½, {len(events_detected)} äº‹ä»¶")
        
        return results
    
    def _extract_user_info(self, content: str) -> List[Dict]:
        """æå–ç”¨æˆ·ä¿¡æ¯"""
        updates = []
        
        for field, patterns in self.extraction_patterns.items():
            for pattern, confidence in patterns:
                match = re.search(pattern, content)
                if match:
                    value = self._extract_value(match, field)
                    if value:
                        old_value = getattr(self.memory.user_profile, field, None)
                        if old_value and old_value != value:
                            continue
                        
                        self.memory.update_user_profile(field, value)
                        updates.append({
                            "field": field,
                            "value": value,
                            "confidence": confidence
                        })
                        break
        
        return updates
    
    def _extract_value(self, match, field: str) -> Optional[str]:
        """ä»åŒ¹é…ä¸­æå–å€¼"""
        if field == "birthday":
            groups = match.groups()
            if len(groups) == 2:
                month, day = groups
                return f"{datetime.now().year}-{int(month):02d}-{int(day):02d}"
            elif len(groups) == 3:
                year, month, day = groups
                return f"{year}-{int(month):02d}-{int(day):02d}"
        else:
            return match.group(1).strip()
        
        return None
    
    def _extract_preferences(self, content: str) -> List[Dict]:
        """æå–ç”¨æˆ·åå¥½"""
        updates = []
        
        for category, patterns in self.preference_patterns.items():
            for pattern, value_extractor, confidence in patterns:
                match = re.search(pattern, content)
                if match:
                    if callable(value_extractor):
                        value = value_extractor(match)
                    else:
                        value = value_extractor
                    
                    if value:
                        self.memory.update_preference(
                            key=category,
                            value=value,
                            category="preference",
                            confidence=confidence
                        )
                        updates.append({
                            "category": category,
                            "value": value,
                            "confidence": confidence
                        })
                        break
        
        return updates
    
    def _extract_events(self, content: str) -> List[Dict]:
        """æå–é‡è¦äº‹ä»¶"""
        events = []
        today = datetime.now()
        
        for pattern, event_type in self.event_patterns:
            match = re.search(pattern, content)
            if match:
                groups = match.groups()
                
                if event_type == "date_event":
                    if len(groups) == 3:
                        month, day, title = groups
                        event_date = f"{today.year}-{int(month):02d}-{int(day):02d}"
                    elif len(groups) == 4:
                        year, month, day, title = groups
                        event_date = f"{year}-{int(month):02d}-{int(day):02d}"
                    else:
                        continue
                    
                    self.memory.add_important_event(
                        title=title,
                        event_date=event_date,
                        event_type="user_mentioned"
                    )
                    events.append({
                        "title": title,
                        "date": event_date,
                        "type": event_type
                    })
                
                elif event_type == "tomorrow_event":
                    title = groups[0]
                    event_date = (today + __import__('datetime').timedelta(days=1)).strftime("%Y-%m-%d")
                    self.memory.add_important_event(
                        title=title,
                        event_date=event_date,
                        event_type="user_mentioned"
                    )
                    events.append({
                        "title": title,
                        "date": event_date,
                        "type": event_type
                    })
                
                elif event_type == "day_after_event":
                    title = groups[0]
                    event_date = (today + __import__('datetime').timedelta(days=2)).strftime("%Y-%m-%d")
                    self.memory.add_important_event(
                        title=title,
                        event_date=event_date,
                        event_type="user_mentioned"
                    )
                    events.append({
                        "title": title,
                        "date": event_date,
                        "type": event_type
                    })
        
        return events
    
    def _extract_important_info(self, content: str) -> List[str]:
        """æå–é‡è¦ä¿¡æ¯ä½œä¸ºå¤‡å¿˜"""
        notes = []
        
        for keyword in self.important_keywords:
            if keyword in content:
                sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\n]', content)
                for sentence in sentences:
                    if keyword in sentence and len(sentence) > 5:
                        self.memory.add_memory_note(
                            content=sentence.strip(),
                            category="important",
                            priority=7,
                            source="auto_extracted"
                        )
                        notes.append(sentence.strip())
                        break
        
        return notes
    
    def learn_from_conversation(self, messages: List[Dict]) -> Dict:
        """
        ä»å®Œæ•´å¯¹è¯ä¸­å­¦ä¹ 
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨ [{"role": "user/assistant", "content": "..."}]
        
        Returns:
            å­¦ä¹ ç»“æœæ±‡æ€»
        """
        results = {
            "total_learned": 0,
            "profile_updates": [],
            "preference_updates": [],
            "events_detected": [],
            "notes_added": []
        }
        
        for message in messages:
            if message.get("role") == "user":
                msg_result = self.learn_from_message(
                    message["role"],
                    message["content"]
                )
                
                if msg_result.get("learned"):
                    results["total_learned"] += 1
                    results["profile_updates"].extend(msg_result.get("profile_updates", []))
                    results["preference_updates"].extend(msg_result.get("preference_updates", []))
                    results["events_detected"].extend(msg_result.get("events_detected", []))
                    results["notes_added"].extend(msg_result.get("notes_added", []))
        
        if results["total_learned"] > 0:
            logger.info(f"ğŸ§  ä»å¯¹è¯ä¸­å­¦ä¹ å®Œæˆ: {results['total_learned']} æ¡æ–°ä¿¡æ¯")
        
        return results
    
    def summarize_conversation(self, messages: List[Dict]) -> str:
        """
        æ€»ç»“å¯¹è¯å†…å®¹
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
        
        Returns:
            å¯¹è¯æ‘˜è¦
        """
        user_messages = [
            m["content"] for m in messages 
            if m.get("role") == "user"
        ]
        
        if not user_messages:
            return ""
        
        topics = []
        
        action_keywords = ["å‘é‚®ä»¶", "æŸ¥å¤©æ°”", "å®šé—¹é’Ÿ", "æé†’", "æœç´¢", "æ’­æ”¾", "ä¸‹è½½", "ä¿å­˜"]
        for msg in user_messages:
            for keyword in action_keywords:
                if keyword in msg:
                    topics.append(f"ç”¨æˆ·è¯·æ±‚{keyword}")
                    break
        
        if topics:
            summary = f"å¯¹è¯æ¶‰åŠ: {', '.join(set(topics[:5]))}"
        else:
            summary = f"å¯¹è¯åŒ…å« {len(user_messages)} æ¡ç”¨æˆ·æ¶ˆæ¯"
        
        return summary


memory_learner = MemoryLearner()
