"""
LLM Agent - å¤§æ¨¡å‹å¯¹è¯æ™ºèƒ½ä½“
ç›´æ¥ä¸ LLM å¯¹è¯ï¼Œä¸ç»è¿‡æ„å›¾è¯†åˆ«
"""
from typing import Any, Dict, Optional
from loguru import logger

from ..base import BaseAgent, Task


class LLMAgent(BaseAgent):
    """
    LLM å¯¹è¯æ™ºèƒ½ä½“ - ç›´æ¥ä¸ LLM äº¤äº’
    
    èŒè´£ï¼š
    1. ç›´æ¥å“åº”ç”¨æˆ·çš„å¯¹è¯è¯·æ±‚
    2. ä¸ç»è¿‡æ„å›¾è¯†åˆ«ï¼Œç›´æ¥è°ƒç”¨ LLM
    3. æ”¯æŒå¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡
    """
    
    KEYWORD_MAPPINGS = {
        "é—®å¤§æ¨¡å‹": ("chat", {}),
        "é—®ai": ("chat", {}),
        "é—®äººå·¥æ™ºèƒ½": ("chat", {}),
        "ç›´æ¥é—®": ("chat", {}),
        "å’ŒaièŠå¤©": ("chat", {}),
        "å’Œå¤§æ¨¡å‹èŠå¤©": ("chat", {}),
        "é—®llm": ("chat", {}),
    }
    
    def __init__(self):
        super().__init__(
            name="llm_agent",
            description="LLMå¯¹è¯æ™ºèƒ½ä½“ - ç›´æ¥ä¸å¤§æ¨¡å‹å¯¹è¯ï¼Œä¸ç»è¿‡æ„å›¾è¯†åˆ«"
        )
        
        self.register_capability("llm_chat", "LLMå¯¹è¯")
        self.register_capability("direct_chat", "ç›´æ¥å¯¹è¯")
        self.register_capability("conversation", "å¯¹è¯")
        
        self._llm_gateway = None
        self._conversation_history: list = []
        self._max_history = 10
    
    def _get_llm_gateway(self):
        """è·å– LLM ç½‘å…³"""
        if self._llm_gateway is None:
            from ...llm import LLMGateway
            from ...config import settings
            self._llm_gateway = LLMGateway(settings.llm)
        return self._llm_gateway
    
    async def execute_task(self, task: Task) -> Any:
        """æ‰§è¡Œä»»åŠ¡"""
        task_type = task.type
        params = task.params
        
        logger.info(f"ğŸ¤– LLM æ™ºèƒ½ä½“æ‰§è¡Œä»»åŠ¡: {task_type}")
        
        if task_type == "chat":
            return await self._chat(params)
        elif task_type == "clear_history":
            return await self._clear_history(params)
        else:
            return await self._chat(params)
    
    async def _chat(self, params: Dict) -> str:
        """ç›´æ¥ä¸ LLM å¯¹è¯"""
        user_input = params.get("query", "") or params.get("message", "") or params.get("original_text", "")
        
        if not user_input:
            return "è¯·è¾“å…¥æ‚¨æƒ³é—®çš„é—®é¢˜"
        
        try:
            llm = self._get_llm_gateway()
            
            self._conversation_history.append({
                "role": "user",
                "content": user_input
            })
            
            if len(self._conversation_history) > self._max_history * 2:
                self._conversation_history = self._conversation_history[-self._max_history * 2:]
            
            response = await llm.chat(self._conversation_history)
            
            if response and response.content:
                self._conversation_history.append({
                    "role": "assistant",
                    "content": response.content
                })
                
                return response.content
            else:
                return "æŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜"
                
        except Exception as e:
            logger.error(f"LLM å¯¹è¯å¤±è´¥: {e}")
            return f"å¯¹è¯å‡ºé”™: {str(e)}"
    
    async def _clear_history(self, params: Dict) -> str:
        """æ¸…ç©ºå¯¹è¯å†å²"""
        self._conversation_history = []
        return "âœ… å¯¹è¯å†å²å·²æ¸…ç©º"
    
    def get_capabilities(self) -> Dict[str, Any]:
        """è·å–æ™ºèƒ½ä½“èƒ½åŠ›"""
        return {
            "name": self.name,
            "description": self.description,
            "capabilities": self._capabilities,
            "keyword_mappings": self.KEYWORD_MAPPINGS,
            "supports_conversation": True,
        }
